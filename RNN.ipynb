{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. extract dataset of pubmed abstract (a part)\n",
    "2. convert them into tokens\n",
    "3. pad them into same length for batch\n",
    "4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function is_available in module torch.cuda:\n",
      "\n",
      "is_available() -> bool\n",
      "    Returns a bool indicating if CUDA is currently available.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.cuda.is_available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@VersuS_/coding-a-recurrent-neural-network-rnn-from-scratch-using-pytorch-a6c9fc8ed4a7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "from data.data_extract import load_pubmed_extracted\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "vocab_file_path = 'bert_tokenizer/bert_toy-vocab.txt'\n",
    "tokenizer = BertTokenizer(vocab_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_pubmed_extracted('D:/data_phd_code_from_scatch/datasets/pubmed_abstracts.json')\n",
    "texts = [entry['text'] for entry in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize texts\n",
    "tokenized_texts  = [tokenizer.encode(text, add_special_tokens=False) for text in texts]\n",
    "\n",
    "# Create input-target pairs\n",
    "input_sequences = [tokens[:-1] for tokens in tokenized_texts]  # All except last token\n",
    "target_sequences = [tokens[1:] for tokens in tokenized_texts]  # All except first token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "input_tensors = torch.nn.utils.rnn.pad_sequence(\n",
    "    [torch.tensor(seq) for seq in input_sequences],\n",
    "    batch_first=True,\n",
    "    padding_value=0\n",
    ")\n",
    "target_tensors = torch.nn.utils.rnn.pad_sequence(\n",
    "    [torch.tensor(seq) for seq in target_sequences],\n",
    "    batch_first=True,\n",
    "    padding_value=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensors saved to D:/data_phd_code_from_scatch/datasets/data_processed/pubmed_a_part_abstract/input_tensors.pt\n",
      "Target tensors saved to D:/data_phd_code_from_scatch/datasets/data_processed/pubmed_a_part_abstract/target_tensors.pt\n"
     ]
    }
   ],
   "source": [
    "# File paths to save tensors\n",
    "path = 'D:/data_phd_code_from_scatch/datasets/data_processed/pubmed_a_part_abstract/'\n",
    "input_tensor_file = path + 'input_tensors.pt'\n",
    "target_tensor_file = path + 'target_tensors.pt'\n",
    "# Save tensors to files\n",
    "torch.save(input_tensors, input_tensor_file)\n",
    "torch.save(target_tensors, target_tensor_file)\n",
    "\n",
    "print(f\"Input tensors saved to {input_tensor_file}\")\n",
    "print(f\"Target tensors saved to {target_tensor_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Input Tensors: tensor([[    4,    16,    16,  ...,     0,     0,     0],\n",
      "        [  150,  1795,  1071,  ...,     0,     0,     0],\n",
      "        [  150, 20827,   242,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [10016,   749,   431,  ...,     0,     0,     0],\n",
      "        [   40,  4635,   178,  ...,     0,     0,     0],\n",
      "        [ 1968,  5420,   231,  ...,     0,     0,     0]])\n",
      "Loaded Target Tensors: tensor([[   16,    16,    12,  ...,     0,     0,     0],\n",
      "        [ 1795,  1071,  2327,  ...,     0,     0,     0],\n",
      "        [20827,   242,   178,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  749,   431,   242,  ...,     0,     0,     0],\n",
      "        [ 4635,   178,   294,  ...,     0,     0,     0],\n",
      "        [ 5420,   231, 17803,  ...,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# File paths to save tensors\n",
    "path = 'D:/data_phd_code_from_scatch/datasets/data_processed/pubmed_a_part_abstract/'\n",
    "input_tensor_file = path + 'input_tensors.pt'\n",
    "target_tensor_file = path + 'target_tensors.pt'\n",
    "# Load tensors\n",
    "input_tensors = torch.load(input_tensor_file)\n",
    "target_tensors = torch.load(target_tensor_file)\n",
    "\n",
    "print(\"Loaded Input Tensors:\", input_tensors)\n",
    "print(\"Loaded Target Tensors:\", target_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\"\"\"\n",
    "\n",
    "Text Dataset\n",
    "Text Dataset Class\n",
    "\n",
    "This class is in charge of managing text data as vectors\n",
    "Data is saved as vectors (not as text)\n",
    "Attributes\n",
    "----------\n",
    "seq_length - int: Sequence length\n",
    "chars - list(str): List of characters\n",
    "char_to_idx - dict: dictionary from character to index\n",
    "idx_to_char - dict: dictionary from index to character\n",
    "vocab_size - int: Vocabulary size\n",
    "data_size - int: total length of the text\n",
    "\n",
    "\n",
    "It returns a tuple (X, y) where:\n",
    "\n",
    "X: A sequence of characters converted into numerical indices (a tensor of size seq_length).\n",
    "y: The same sequence as X, but shifted left by one character (a tensor of size seq_length).\n",
    "\"\"\"\n",
    "class TextDataset(Dataset):\n",
    "   def __init__(self,text_data,tokenizer, seq_len = 100):\n",
    "         self.text_data = text_data\n",
    "         self.tokenizer = tokenizer\n",
    "         self.seq_len = seq_len\n",
    "   \n",
    "   def __len__(self):\n",
    "        \"\"\"Returns the total number of samples.\"\"\"\n",
    "        return len(self.text_data)\n",
    "   \n",
    "   def __getitem__(self, idx):\n",
    "       in \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478473"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
